---
title: "Replication of Support for Resettling Refugees: The Role of Fixed Versus Growth Mind-Sets by Madan et. al. (2019, Psychological Science)"
author: "Ethan Roy ethanroy@stanford.edu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

For this project, I plan to replicate Madan et. al.'s 2019 study, which explores the connection between a fixed versus growth mindset and how those mindsets impact an individual's openness to supporting refugees in their country. Though my research interests align more closely with the field of educational neuroscience, I am intrigued by the impact a growth mindset can have on student's learning. By replicating this study, I will be able to reflect more on the impact of mindset (growth or fixed) on an individuals openness to new people, cultures, and ways of thinking.  

### Study Description

The study being replicated explored the effect of mindset on an individual's support for refugees in their country. In a series of six experiments, the original authors examined the mindsets (growth or fixed) of individuals in the United States and United Kingdom and their views on if refugees are able to assimilate into a new culture and to what extent are refugees obligated to assimilate to a new society. I plan to replicate the first study, which leverages survey data to ascertain a participant's support for refugees based on their opinions on the type of person someone is, mindset regarding intelligence (fixed vs growth), and political leanings.

#### Stimuli and Procedures

Participants will be recruited through Amazon Mechanical Turk. Per the original study, participants will report some demographic information (gender, age, race). Each participant will have to undergo a pre-screening to ensure that they meet two criteria:

* are a United States Citizen
* currently residing in the United States

Once participants have been screened, they will read a brief paragraph outlining the current refugee resettlement policy of the United States announced by the president in September of 2019. They will then answer a four item questionaire to measure their support for resettling refugees and two eight item questionaires measuring their views on the type of person someone is and their mindsets regarding participants. Participants will be randomly assigned so that half of sample responds to the refugee measure first and half of the sample responds to the mindsets measure first. Finally, participants will respond to a three item survey measuring their political orientation. 

#### Potential Challenges

While replicating this study, I foresee the following challenges:

* having a sufficient sample size to generate a sufficient effect size that also meets the bugetary criteria for this replication
* having enough participants after excluding participants who do not meet the inclusion criteria
* subjects not feeling as strongly about the current U.S refugee resettlement policy due to other political happenings moving into the public spotlight.

### Links

* [Project Repository](https://github.com/psych251/mandan2019)
* [Original Paper](https://github.com/psych251/mandan2019/blob/master/original_paper/mandan2019.pdf)
* [Survey Link](https://stanforduniversity.qualtrics.com/jfe/form/SV_8iCy0tOjjbvXK4J)

## Methods

### Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

The original effect size was r<sup>2</sup> = 0.428. Power analysis using G*Power revealed that the reach certain levels of power the following sample sizes are needed:

* 80% power requires a sample of 22
* 90% power requires a sample of 27
* 95% power requires a sample of 32

Completion of the survey takes about ten minutes. In order to remain consistent with California minimum wage ($7.25/hour), each participant will recieve $1.21 as compensation. To account for the course budget, a minimum sample of 27 will be required to attain 90% power. Though the original paper does not report an explicit exclusion rate, 28 participants will be asked to complete the survey just to account for any participants who do not meet the survey requirements. 

### Planned Sample

The planned sample for this replication will be 28 participants based on the power analysis conducted above. Participants will be screened to ensure that they are citizens of the United States and currently residing in the United States.

### Materials

As quoted from original study:

>"We administered four items to measure participants’ support for resettling refugees, each measured on a 7-point scale: (a) “How much do you agree that the US should take in 110,000 refugees in the next 12 months?” (*strongly disagree to strongly agree*), (b) “How much do you support the policy that the US should take in 110,000 refugees in the next 12 months?” (*strongly against to strongly support*), (c) “Do you think that the United States is taking in too many refugees?” (reverse-coded; *definitely not to definitely yes*), and (d) “Do you think that the United States is taking in too few refugees?” (*definitely not to definitely yes*).
>
We measured participants’ mind-sets about the kind of person someone is using an established eight-item scale (Levy et al., 1998; sample item: “The kind of person someone is, is something basic about them, and it can’t be changed very much”). We also measured participants’ mind-set about intelligence (fixed vs. growth) using the standard eight-item scale (Dweck, 2000; sample item: “People have a certain amount of intelligence, and they can’t really do much to change it”). For both scales, all items were scored such that higher numbers indicated stronger growth kind-of-person mind-sets or mind-sets about intelligence.
>
Finally, because the question of accepting refugees is a highly politicized issue, we measured participants’ political orientation using three items, each measured on a 7-point scale ranging from *strongly conservative* to *strongly liberal* (Item 1), *strongly right* to *strongly left* (Item 2), and *strongly Republican* to *strongly Democrat* (Item 3)."

The exact items, measures, and scales were used in this replication.


### Procedure	

We presented participants with the following paragraph detailing the latest refugee resettlement policy of the United States, which was announced by the U.S. president in September 2019:

>The United States recently revised its policy towards refugees. The President recently signed an order that set the cap on the number of refugees admitted to the United States next year at 18,000, the lowest level since the program began four decades ago. This new cap is down from the last years limit of 30,000. This is the third consecutive year the U.S has reduced the limit of refugees admitted to the United States.  

Participants were then asked to respond to the three measures described in the [Materials]. Half of the participants were randomly assigned to respond to the resettling refugees measure first while the other half responded to the mindsets measures first. After responding to both of those measures, participants responded to the political orientation measures.

### Analysis Plan

First, participants who are not U.S citizens or are U.S citizens living abroad will be excluded from the final sample. 

Next, I will calculate descriptive statistics for each variable (kind of person mindsets, mindsets about intelligence, political orientation, and support for resettling refugees). 

**Key Analysis of Interest:**

I will generate three linear models exploring  participants’ support for resettling refugees as the dependent measure and their kind-of-person mind-sets, mind-sets about intelligence, and political orientation as independent variables. The key statistic comes from a t-test on the correlation coefficient after adding the kind-of-person measure to the linear model. The p-value is reported to be 0.0016 in the original paper.
 
### Differences from Original Study

To ensure stable correlations, the original study recruited 400 participants, even though their power analysis indicated they needed 94 participants. The current study only used 28 subjects based on the aforementioned power analysis and bugetary constraints. 

Per the suggestion of the original author, participants were asked to read a summary of the most recent refugee policy of the United States, instead of the 2016 policy, the year the original study was conducted. The policy outlined in the original study stated that the U.S would increase the number of refugees it admitted, while the current policy states a reduction in the total number of refugees admitted to the United States. 

### Methods Addendum (Post Data Collection)

#### Actual Sample
All 28 participants that responded to the mTurk request were included in the study.  

#### Differences from pre-data collection methods plan
  None

## Results

### Data preparation

Below is the data preparation for the pilot data collected through the direct distribution of my qualtirics survey.

Here we load the knitr library for cleaner table output, the tidyverse library to allow for facilitate working with and exploring the data, the here library to facilitate setting the working directory, and the rgeolocate library to determine the state in which participants completed the survey based on their IP address.

```{r echo=T, results='hide'}

### Pilot Data Preparation

####Load Relevant Libraries and Functions
library(knitr)
library(tidyverse)
library(here)
library(rgeolocate)
```

Next we load the data:
```{r echo=T, results='hide'}
####Import data
#setwd("/Users/Ethan/Documents/Stanford/Fall 2019/Psych 251/mandan2019/Data") #Set working directory

rawData <- read.csv(here("data","finalData.csv"),stringsAsFactors = FALSE)
```

Once the raw data are loaded, we manipulate the data in various ways to allow us to run our statistical tests.

First, we rename the values in the random order column to allow us to more easily determine which measure the particpants viewed first. The value 'mindsetsFirst' means that the participant responded to the mindsets measures before the refugee measure and 'refugeeFirst' means the participant responded to the refugee measure first.
```{r}
#### Data exclusion / filtering

#Rename column with randomizer data and rename values in the randomOrder column to reflect whether that participant saw the mindset questions or refugee questions first
rawData<-rawData %>% rename(randomOrder = "FL_4_DO") %>%
  mutate(randomOrder=recode(randomOrder,'FL_18|Refugee'='mindsetsFirst','Refugee|FL_18'='refugeeFirst'))
```

Then we filtered out any particpants who did not meet our inclusion criteria.

```{r}

filteredData <- filter(rawData, rawData$Citizen==1) 
#filter out any participants who are not US Citizens per original paper
```

Next, we add a column for participant ID. Since each particicpant only spans one row, we can just use the row number as their participant ID. We also recode some of the numeric values collected by Qualtrics, such as Ethnicity and Gender, so they are human readable.
```{r}
#### Prepare data for analysis - create columns etc.

filteredData <- filteredData %>% mutate(ID = row_number()) #give each row a participant ID
filteredData <- filteredData %>% mutate(state = (ip_api(filteredData$IPAddress)$country_code)) #get participants state based on IP address

#Could not get qualtrics to export text and numeric data so decoding from numeric to string values for ethinicity field
filteredData$Ethnicity <- factor(filteredData$Ethnicity, levels = c(15,16,17,18,19,20,21), labels = c("European American", "African American", "Asian American", "Latin American", "Native American", "Multiracial", "Other"))


filteredData$Gender <- factor(filteredData$Gender,levels = c(11,12,13), labels = c("Female", "Male", "Other"))
```

We then take the filtered data and make it 'tidy' so that each answer recorded by a participant becomes a row. This 'gather' generates a column called 'Measure', which refers to the type of question (intelligence, kind of person, political, or refugee) a particpant was responding two. The value for this column are then renamed to just include the measure type and not the question number to allow for grouping. We then group based on the participant ID, order in which participants answered each measure, and measure type and find the average. These grouped data are then spread into wide format so each row contains one participant and each column contains the average value of their responses for each survey measure.  
```{r}
tidyData <- filteredData %>% 
    gather(Measure,Score,contains("Personal"),contains("Intell"),contains("Ref_"),contains("Pol"))


tidyData$Score<-as.numeric(tidyData$Score)

tidyData$Measure[contains("Personal",vars = tidyData$Measure)]<- "personalityMeasure"
tidyData$Measure[contains("Intell",vars = tidyData$Measure)]<- "intelligenceMeasure"
tidyData$Measure[contains("Ref",vars = tidyData$Measure)]<- "refugeeMeasure"
tidyData$Measure[contains("Pol",vars = tidyData$Measure)]<- "politicalMeasure"
#refer all questions within each measure by that measure instead of measure_questionNumber

modelDataTidy <-tidyData %>% 
  group_by(ID,randomOrder,Measure,state) %>% 
  summarise(meanScores=mean(Score,na.rm=T))

modelData <- modelDataTidy %>% 
  spread(Measure,meanScores)
#spread so each participant is in one row and mean scores for each measure are the columns

kable(modelData)

```

### Participant Demographics



**Number of subjects in replication:**

```{r}

  length(modelData$ID)

```

**Age (in years):**

```{r }
  
  ageBreakdown <- filteredData %>% 
    summarise(Average=mean(as.numeric(Age)), SD=sd(as.numeric(Age)))
  
  kable(ageBreakdown)

```

**Gender:**
```{r }

  genderBreakdown <- filteredData %>% 
    group_by(Gender) %>% 
    summarise(Count=length(Gender), Percentage = length(Gender)/length(filteredData$Gender)*100)

  kable(genderBreakdown)

```

**Ethnicity:**

```{r }

  ethnicityBreakdown <- filteredData %>% 
    group_by(Ethnicity) %>% 
    summarise(Count=length(Ethnicity), Percentage = length(Ethnicity)/length(filteredData$Ethnicity)*100)

  kable(ethnicityBreakdown)

```

**Geographic Breakdown**

Counts of how many respondants per state and the average political views of those respondants.
```{r }

  geoBreakdown <- modelData %>% 
    group_by(state) %>% 
    summarise(Count=length(state), Percentage = (length(state))/length(modelData$state)*100, Average_Political_Score = mean(politicalMeasure))

  kable(geoBreakdown[order(-geoBreakdown$Average_Political_Score),])

```

**Political Beliefs**

```{r }

polBreakdownAvg <- paste("Average: ", toString(mean(modelData$politicalMeasure)))
polBreakdownSD <- paste("SD: ", toString(sd(modelData$politicalMeasure)))
  
polBreakdownAvg
polBreakdownSD

```

**Exploratory Visualizations**

```{r }
#exploratory demographic histogram to see age distributions by gender and ethnicity

sortedAges <- sort(filteredData$Age)

ggplot(filteredData, aes(x = Age, group = Ethnicity))+
  geom_histogram(stat="count",binwidth = 1) +
  theme_bw()+
  scale_x_discrete(breaks = c("25","28","32","36","38","41","46","56"))+ 
  #these hardcoded values worked best for the axis to look decent. Otherwise there were big jumps in the tick marks
  theme(axis.text.x=element_text(angle=45))+
  facet_grid(Gender~Ethnicity)

```

```{r warning=FALSE}
#exploratory political histogram to see distributions by political views

ggplot(modelData, aes(x = politicalMeasure))+
  geom_histogram(stat="count",binwidth = 1) +
  theme_bw()+
  theme(axis.text.x=element_text(angle=45))

```

### Confirmatory analysis

As done in the original study, I built three linear models. The first one looked at how mindsets about intelligence predict support for refugees. The next model added political orientation to the independent variables and the third model added kind of person mindsets. I also ran another regression examining the effect the order of the survey measures (support for resettling refugees measure first or mindsets measures first) and the interaction between kind of person mindsets and presentation order have on participant's support for resettling refugees. The key statistic will be a t statistic exploring whether the third model (which includes the kind of person mindset measure) differs significantly from the models that do not include that measure.

**Summary of Model 1:**
```{r }

model1 <- lm(refugeeMeasure ~ intelligenceMeasure, d=modelData)
summary(model1)
```

**Summary of Model 2:**
```{r}
model2 <- lm(refugeeMeasure ~ intelligenceMeasure+politicalMeasure, d=modelData)
summary(model2)
```

**Summary of Model 3:**

*Key Statistical test*
```{r}
model3 <- lm(refugeeMeasure ~ intelligenceMeasure+politicalMeasure+personalityMeasure, d=modelData)
summary(model3)
```

**Summary of Model 4:**
```{r}
model4 <- lm(refugeeMeasure ~ intelligenceMeasure + politicalMeasure + personalityMeasure + randomOrder + personalityMeasure*randomOrder, d=modelData)
summary(model4)

```


### Exploratory analyses

Due to the nature of the regressions, the original paper has no figures, however, I have included scatter plots exploring the relationship between the mindsets/political measures and the openness to refugees measure. 

*Plot of First Linear Model*

This plot looks at the relationship between the intelligence measure and the refugee measure.
```{r }

modelData %>% 
  ggplot(aes(x = intelligenceMeasure, y = refugeeMeasure)) +
  xlim(0,7)+
  ylim(0,7)+
  geom_jitter(aes(colour = randomOrder), width = 0.2, height = 0.4) + 
  geom_smooth(method=lm, se=FALSE,fullrange=TRUE)+
  theme(panel.background = element_rect(fill=FALSE),
        axis.line = element_line(colour='black'))

summary(model1)

```

*Plot of Second Linear Model*
This plot looks at the relationship between the political measure and the refugee measure.
```{r, warning=FALSE}

modelData %>% 
  ggplot(aes(x = politicalMeasure, y = refugeeMeasure)) +
  xlim(0,7)+
  ylim(0,7)+
  geom_jitter(aes(colour = randomOrder), width = 0.2, height = 0.4) + 
  geom_smooth(method=lm, se=FALSE,fullrange=TRUE)+
  theme(panel.background = element_rect(fill=FALSE),
        axis.line = element_line(colour='black'))

model = lm(refugeeMeasure~politicalMeasure, d=modelData)
summary(model)

```

*Plot of Third Linear Model*
This plot looks at the relationship between the personality measure and the refugee measure.
```{r, warning=FALSE}

modelData %>%
  ggplot(aes(x = personalityMeasure, y = refugeeMeasure)) +
  xlim(0,7)+
  ylim(0,7)+
  geom_jitter(aes(colour = randomOrder), width = 0.2, height = 0.4) +
  geom_smooth(method=lm, se=FALSE,fullrange=TRUE)+
  theme(panel.background = element_rect(fill=FALSE),
        axis.line = element_line(colour='black'))

model = lm(refugeeMeasure~personalityMeasure, d=modelData)
summary(model)
```

**Comparison of First Three Models **


```{r}

comp = anova(model1,model2,model3, test="Chisq")

comp

```


**T-test comparing the random order groups**

After graphing the various measures against the refugee measure, I noticed that the random order groups seemed clustered. Here I run a t-test to see if order a participant responded to the survey measures impacted their attititudes towards refugees. 

```{r}
t.test(modelData$refugeeMeasure~modelData$randomOrder)
```

## Discussion

### Summary of Replication Attempt

The confirmatory analysis found that an individual's attitude towards a person being able change (growth mindset) did not significantly predict their attitude towards welcoming refugees into their country (t(24) = -0.927, p = 0.363). This failed to replicate the original result, which found the more a person held a growth mindset, the more welcoming they were to refugees (t(400) = 3.17, p=.0016).

### Commentary

Exploratory plotting of the three single variable models reinforced the notion that none of the predictor variables correlated with the criterion variable. However, these plots did highlight a potential difference between the participants who answered the refugee measure first and those who answered the mindsets measures first. After running a two sample t-test, the observed differences based on the graph clusters was  found to be significant (p=0.009), indicating that the order the measures were presented impacted how participants responded to the refugee measure. The original authors also conducted an analysis looking at the impact stimulus order had on responses to the refugee measure and did not find a significant result.

Additional exploratory plots revealed that the political views of the current participants skewed heavily to the left (mean=5.178571	sd = 1.688699), which may have had an impact on the present failure to replicate the original study. The original study did not include any these plots but reported an average score on the political measure of 4.38 with a standard deviation of 1.66. This suggests that the original study used either a more moderate or a more politically diverse sample than the present study. 

Another possible explaination for the present failure to replicate was proposed by the original author. She suggested that "all the dependent variables across all studies reference to refugee policies that were just announced/top of mind in news media and widely debated", which may impact the current study. When the original study was conducted, immigration was a salient issue in the U.S media, whereas, at the time of the present study, other issues have moved into the media spotlight. The impact of the news media cycle may also serve to explain the present failure to replicate.

Aside from the concerns about the impact of media coverage, the original authors did not raise any objections or challenges about the present replication attempt. 
